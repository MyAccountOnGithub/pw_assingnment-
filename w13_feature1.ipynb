{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29411d9f-9b4d-45ad-8377-af9c55799cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In simple words, filter methods for feature selection in machine learning are a way to pick the most valuable information from a large data set \\nthat can help your model make better predictions. It's like looking for the needle in a haystack, where the needle is the essential feature that is \\nrelevant to your problem.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. What is the Filter method in feature selection, and how does it work?\n",
    "'''In simple words, filter methods for feature selection in machine learning are a way to pick the most valuable information from a large data set \n",
    "that can help your model make better predictions. It's like looking for the needle in a haystack, where the needle is the essential feature that is \n",
    "relevant to your problem.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ab2170-3bb4-4162-b03a-320d01283170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filter methods might fail to find the best subset of features in many occasions but wrapper methods can always provide the best subset of features.\\nUsing the subset of features from the wrapper methods make the model more prone to overfitting as compared to using subset of features from the filter\\nmethods'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "'''Filter methods might fail to find the best subset of features in many occasions but wrapper methods can always provide the best subset of features.\n",
    "Using the subset of features from the wrapper methods make the model more prone to overfitting as compared to using subset of features from the filter\n",
    "methods'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684e84e1-cabd-47b5-af7f-35d94dc6e7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some examples of embedded methods include decision tree-based algorithms (e.g., decision tree, random forest, gradient boosting), and feature \\nselection using regularization models (e.g., LASSO or elastic net).'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "'''Some examples of embedded methods include decision tree-based algorithms (e.g., decision tree, random forest, gradient boosting), and feature \n",
    "selection using regularization models (e.g., LASSO or elastic net).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8644898-6a64-4504-9157-e96fb7d587eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The common disadvantage of filter methods is that they ignore the interaction with the classifier and each feature is considered independently thus\\nignoring feature dependencies In addition, it is not clear how to determine the threshold point for rankings to select only the required features and\\nexclude noise.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "'''The common disadvantage of filter methods is that they ignore the interaction with the classifier and each feature is considered independently thus\n",
    "ignoring feature dependencies In addition, it is not clear how to determine the threshold point for rankings to select only the required features and\n",
    "exclude noise.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fccc3c6-630f-4669-a30f-09dbc963fb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You may wish to use Filter methods because they are computationally less expensive or a combination of Filter and Wrapper methods; also known as \\nHybrid Feature Selection. First, use Filter methods to eliminate redundant features and then, Wrapper methods to select a useful subset'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
    "'''You may wish to use Filter methods because they are computationally less expensive or a combination of Filter and Wrapper methods; also known as \n",
    "Hybrid Feature Selection. First, use Filter methods to eliminate redundant features and then, Wrapper methods to select a useful subset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ab87b3-5a6d-4061-814b-47ddd087a803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mobel for customer churn in a telelcom system we follow the step that is \\n1.Understand the Problem\\n2.Data Collection and Preprocessing\\n3.Correlation Analysis\\n4.Feature Selection\\n5.Model Building\\n6.Model Evaluation and Refinement'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.You are unsure of which features to include in\n",
    "#the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the \n",
    "#Filter Method.\n",
    "'''Mobel for customer churn in a telelcom system we follow the step that is \n",
    "1.Understand the Problem\n",
    "2.Data Collection and Preprocessing\n",
    "3.Correlation Analysis\n",
    "4.Feature Selection\n",
    "5.Model Building\n",
    "6.Model Evaluation and Refinement'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f22514b-3365-4852-b582-528f1ea8d28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1.Choose a Suitable Algorithm\\nLasso (L1 Regularization) Regression: Penalizes the absolute size of coefficients, driving some coefficients to zero, effectively performing feature selection.\\nTree-based methods: Algorithms like Decision Trees, Random Forests, and Gradient Boosting Trees can evaluate the importance of each feature.\\n2.Prepare the Data\\n3. Train the Model with Regularization\\n4. Evaluate Feature Importance\\n5. Select Relevant Features\\n6. Retrain the Model\\nUsing the Embedded method for feature selection leverages the model's own process of fitting the data to identify the most important features. This not only improves\\nthe model's performance but also reduces overfitting and enhances interpretability. For predicting soccer match outcomes, features like player statistics, team rankings, \\nand historical match data will likely emerge as significant predictors when using this approach.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics\n",
    "# and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.\n",
    "'''1.Choose a Suitable Algorithm\n",
    "Lasso (L1 Regularization) Regression: Penalizes the absolute size of coefficients, driving some coefficients to zero, effectively performing feature selection.\n",
    "Tree-based methods: Algorithms like Decision Trees, Random Forests, and Gradient Boosting Trees can evaluate the importance of each feature.\n",
    "2.Prepare the Data\n",
    "3. Train the Model with Regularization\n",
    "4. Evaluate Feature Importance\n",
    "5. Select Relevant Features\n",
    "6. Retrain the Model\n",
    "Using the Embedded method for feature selection leverages the model's own process of fitting the data to identify the most important features. This not only improves\n",
    "the model's performance but also reduces overfitting and enhances interpretability. For predicting soccer match outcomes, features like player statistics, team rankings, \n",
    "and historical match data will likely emerge as significant predictors when using this approach.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d447f4-23cc-420c-b972-bea96681ac8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Workflow:\\nSplit the data into training and testing sets.\\nChoose a model and performance metric.\\nApply the Wrapper method (e.g., RFE) to select the best subset of features.\\nTrain the model using the selected features.\\nEvaluate the performance on the testing set.\\nIterate and experiment with different models and subset sizes if necessary.\\n\\nhe Wrapper method is a powerful feature selection technique that can lead to a model with better performance by selecting the most relevant features.\\nFor predicting house prices, features such as size, location, age, and other property-specific attributes will likely emerge as significant predictors\\nwhen using this approach. The iterative nature of the Wrapper method ensures that the selected features contribute the most to the model’s accuracy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8. You are working on a project to predict the price of a house based on its features, such as size, location,and age. You have a limited number of\n",
    "# features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the\n",
    "#best set of features for the predictor.\n",
    "'''Workflow:\n",
    "Split the data into training and testing sets.\n",
    "Choose a model and performance metric.\n",
    "Apply the Wrapper method (e.g., RFE) to select the best subset of features.\n",
    "Train the model using the selected features.\n",
    "Evaluate the performance on the testing set.\n",
    "Iterate and experiment with different models and subset sizes if necessary.\n",
    "\n",
    "he Wrapper method is a powerful feature selection technique that can lead to a model with better performance by selecting the most relevant features.\n",
    "For predicting house prices, features such as size, location, age, and other property-specific attributes will likely emerge as significant predictors\n",
    "when using this approach. The iterative nature of the Wrapper method ensures that the selected features contribute the most to the model’s accuracy'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f2977-d0a8-4ed3-aa7f-431e570eba40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
