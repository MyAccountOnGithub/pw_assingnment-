{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99da5669-10b1-4e3c-8d85-c3bb64b71ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To find the probability that an employee is a smoker given that they use the company's health insurance plan, we can use the concept of conditional probability.\\n\\nGiven:\\nThe probability that an employee uses the health insurance plan (\\nP(H)) is 70%, or 0.7.\\nThe probability that an employee is a smoker given that they use the health insurance plan (\\nP(S∣H)) is 40%, or 0.4.\\nWe want to find \\nP(S∣H), which is already given as 0.4.\\nTherefore, the probability that an employee is a smoker given that they use the health insurance plan is 0.4, or 40%.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "# company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "# probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "'''To find the probability that an employee is a smoker given that they use the company's health insurance plan, we can use the concept of conditional probability.\n",
    "\n",
    "Given:\n",
    "The probability that an employee uses the health insurance plan (\n",
    "P(H)) is 70%, or 0.7.\n",
    "The probability that an employee is a smoker given that they use the health insurance plan (\n",
    "P(S∣H)) is 40%, or 0.4.\n",
    "We want to find \n",
    "P(S∣H), which is already given as 0.4.\n",
    "Therefore, the probability that an employee is a smoker given that they use the health insurance plan is 0.4, or 40%.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aca7e55-6875-48a2-b0c2-abf52f9e5c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bernoulli Naive Bayes\\nData Type:\\nDesigned for binary/boolean data.\\nFeatures are binary values indicating the presence (1) or absence (0) of a feature.\\nModel Assumption:\\nAssumes that the features follow a Bernoulli distribution.\\nEach feature is treated as a binary indicator.\\n\\n\\nMultinomial Naive Bayes\\nData Type:\\nDesigned for discrete count data.\\nFeatures represent the frequency or count of occurrences of events.\\nModel Assumption:\\nAssumes that the features follow a multinomial distribution.\\nSuitable for feature vectors where each feature is a count of the number of times an event occurs.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "'''Bernoulli Naive Bayes\n",
    "Data Type:\n",
    "Designed for binary/boolean data.\n",
    "Features are binary values indicating the presence (1) or absence (0) of a feature.\n",
    "Model Assumption:\n",
    "Assumes that the features follow a Bernoulli distribution.\n",
    "Each feature is treated as a binary indicator.\n",
    "\n",
    "\n",
    "Multinomial Naive Bayes\n",
    "Data Type:\n",
    "Designed for discrete count data.\n",
    "Features represent the frequency or count of occurrences of events.\n",
    "Model Assumption:\n",
    "Assumes that the features follow a multinomial distribution.\n",
    "Suitable for feature vectors where each feature is a count of the number of times an event occurs.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1557a8-211c-466a-9b95-958369178e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bernoulli Naive Bayes handles missing values using several common strategies:\\n\\nIgnore Missing Values: Exclude instances with missing values.\\nImpute Missing Values: Replace missing values with the mode (most frequent value) of the feature.\\nUse Probabilistic Imputation: Replace missing values based on the probability of presence (1) or absence (0) calculated from the existing data.\\nTreat Missing Values as a Separate Category: Introduce a new category (e.g., -1) for missing values and modify the model accordingly.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "'''Bernoulli Naive Bayes handles missing values using several common strategies:\n",
    "\n",
    "Ignore Missing Values: Exclude instances with missing values.\n",
    "Impute Missing Values: Replace missing values with the mode (most frequent value) of the feature.\n",
    "Use Probabilistic Imputation: Replace missing values based on the probability of presence (1) or absence (0) calculated from the existing data.\n",
    "Treat Missing Values as a Separate Category: Introduce a new category (e.g., -1) for missing values and modify the model accordingly.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5118b6-806a-460c-97b4-6c34626d830c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How Gaussian Naive Bayes Handles Multi-Class Classification:\\nClass Probabilities:\\n\\nFor each class, Gaussian Naive Bayes calculates the probability of the data point belonging to that class using the Gaussian distribution.\\nFeature Distribution:\\n\\nAssumes that the features are normally distributed within each class.\\nFor each class \\nk, it estimates the mean and variance of each feature \\nXi and uses these to calculate the likelihood of the features given the class.\\nClassification:\\n\\nThe algorithm computes the posterior probability for each class using Bayes' theorem.\\nFor a new instance, it selects the class with the highest posterior probability.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "'''How Gaussian Naive Bayes Handles Multi-Class Classification:\n",
    "Class Probabilities:\n",
    "\n",
    "For each class, Gaussian Naive Bayes calculates the probability of the data point belonging to that class using the Gaussian distribution.\n",
    "Feature Distribution:\n",
    "\n",
    "Assumes that the features are normally distributed within each class.\n",
    "For each class \n",
    "k, it estimates the mean and variance of each feature \n",
    "Xi and uses these to calculate the likelihood of the features given the class.\n",
    "Classification:\n",
    "\n",
    "The algorithm computes the posterior probability for each class using Bayes' theorem.\n",
    "For a new instance, it selects the class with the highest posterior probability.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad4b07-87de-4bfc-ae2f-396b62abf595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
