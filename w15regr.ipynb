{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf47b91-1759-47cd-8fad-7ec7f3c1d38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In simple linear regression model show the relationship between the 1 independent variable and 1 dependent variable where as in multiple linear \\nregression more than 1 independent variable and 1 dependent variable\\nex:Suppose we want to predict a person's weight (y) based on their height (x). In this case, weight is the dependent variable, and height is the \\nindependent variable\\nex:Suppose we want to predict a person's weight (y) based on their height (x1) and age (x2). In this case, weight is the dependent variable, and \\nheight and age are the independent variables.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "'''In simple linear regression model show the relationship between the 1 independent variable and 1 dependent variable where as in multiple linear \n",
    "regression more than 1 independent variable and 1 dependent variable\n",
    "ex:Suppose we want to predict a person's weight (y) based on their height (x). In this case, weight is the dependent variable, and height is the \n",
    "independent variable\n",
    "ex:Suppose we want to predict a person's weight (y) based on their height (x1) and age (x2). In this case, weight is the dependent variable, and \n",
    "height and age are the independent variables.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276f8de8-a0ea-47d9-8478-b08c2f128dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Linearity:\\n\\nAssumption: The relationship between the dependent and independent variables should be linear.\\nCheck: Scatter plots and residual plots (residuals vs. fitted values) should show a linear relationship and no clear pattern, respectively.\\nIndependence:\\n\\nAssumption: Observations should be independent of each other.\\nCheck: Context-specific; for time series data, use the Durbin-Watson test for autocorrelation.\\nHomoscedasticity:\\n\\nAssumption: The residuals should have constant variance at all levels of the independent variables.\\nCheck: Plot residuals vs. fitted values. The spread should be roughly constant. Use the Breusch-Pagan test or White test for formal assessment.\\nNormality of Residuals:\\n\\nAssumption: Residuals should be approximately normally distributed.\\nCheck: Histogram and Q-Q plot of residuals. Perform the Shapiro-Wilk test or Kolmogorov-Smirnov test for formal assessment.\\nNo Multicollinearity (for multiple linear regression):\\n\\nAssumption: Independent variables should not be highly correlated.\\nCheck: Calculate Variance Inflation Factor (VIF); values above 10 (or 5) indicate high multicollinearity. Examine the correlation matrix for high\\ncorrelation coefficients.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "'''Linearity:\n",
    "\n",
    "Assumption: The relationship between the dependent and independent variables should be linear.\n",
    "Check: Scatter plots and residual plots (residuals vs. fitted values) should show a linear relationship and no clear pattern, respectively.\n",
    "Independence:\n",
    "\n",
    "Assumption: Observations should be independent of each other.\n",
    "Check: Context-specific; for time series data, use the Durbin-Watson test for autocorrelation.\n",
    "Homoscedasticity:\n",
    "\n",
    "Assumption: The residuals should have constant variance at all levels of the independent variables.\n",
    "Check: Plot residuals vs. fitted values. The spread should be roughly constant. Use the Breusch-Pagan test or White test for formal assessment.\n",
    "Normality of Residuals:\n",
    "\n",
    "Assumption: Residuals should be approximately normally distributed.\n",
    "Check: Histogram and Q-Q plot of residuals. Perform the Shapiro-Wilk test or Kolmogorov-Smirnov test for formal assessment.\n",
    "No Multicollinearity (for multiple linear regression):\n",
    "\n",
    "Assumption: Independent variables should not be highly correlated.\n",
    "Check: Calculate Variance Inflation Factor (VIF); values above 10 (or 5) indicate high multicollinearity. Examine the correlation matrix for high\n",
    "correlation coefficients.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c08847e-c9e3-4ffe-a1e5-54df7a727975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The line equation y=mx+c where m is the slope and c is the intercept\\nex:Scenario: Predicting House Prices\\nSuppose we are predicting house prices based on the size of the house (in square feet).'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "'''The line equation y=mx+c where m is the slope and c is the intercept\n",
    "ex:Scenario: Predicting House Prices\n",
    "Suppose we are predicting house prices based on the size of the house (in square feet).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79098dc7-cf1a-4993-a6a9-9c3fedaf8ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gradient Descent is an optimization algorithm used to minimize the cost function in machine learning and statistical modeling. It iteratively\\nadjusts the model parameters to find the optimal values that minimize the cost function, which measures how well the model fits the data.\\nit use in\\nLinear Regression: Minimizes the mean squared error between predicted and actual values.\\nLogistic Regression: Minimizes the binary cross-entropy loss.\\nNeural Networks: Minimizes the loss function specific to the problem (e.g., cross-entropy loss for classification, mean squared error for regression).'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "'''Gradient Descent is an optimization algorithm used to minimize the cost function in machine learning and statistical modeling. It iteratively\n",
    "adjusts the model parameters to find the optimal values that minimize the cost function, which measures how well the model fits the data.\n",
    "it use in\n",
    "Linear Regression: Minimizes the mean squared error between predicted and actual values.\n",
    "Logistic Regression: Minimizes the binary cross-entropy loss.\n",
    "Neural Networks: Minimizes the loss function specific to the problem (e.g., cross-entropy loss for classification, mean squared error for regression).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea52afa-7662-4a7f-adfe-0e4aafdb895c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multiple linear regression is an extension of simple linear regression that models the relationship between a dependent variable and two or more\\nindependent variables. The model aims to capture how multiple factors simultaneously affect the dependent variable.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "'''Multiple linear regression is an extension of simple linear regression that models the relationship between a dependent variable and two or more\n",
    "independent variables. The model aims to capture how multiple factors simultaneously affect the dependent variable.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f593097a-fbfd-44bd-a6a8-759d57e33408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multicollinearity occurs when two or more independent variables in a multiple linear regression model are highly correlated, meaning they provide \\nredundant information about the response variable. This can lead to several issues\\nDetection: Use correlation matrix and Variance Inflation Factor (VIF) to identify multicollinearity.\\nAddressing:\\nRemove highly correlated predictors.\\nUse Principal Component Analysis (PCA).\\nApply regularization techniques like Ridge or Lasso regression'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "'''Multicollinearity occurs when two or more independent variables in a multiple linear regression model are highly correlated, meaning they provide \n",
    "redundant information about the response variable. This can lead to several issues\n",
    "Detection: Use correlation matrix and Variance Inflation Factor (VIF) to identify multicollinearity.\n",
    "Addressing:\n",
    "Remove highly correlated predictors.\n",
    "Use Principal Component Analysis (PCA).\n",
    "Apply regularization techniques like Ridge or Lasso regression'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16a926c-bce1-4b76-8b50-a164b0c3b944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polynomial regression is a type of regression analysis in which the relationship between the independent variable x and the dependent variable y \\nis modeled as an n-th degree polynomial. It is used when the data shows a non-linear relationship between the variables.\\nDifferences from Linear Regression:\\nCaptures non-linear relationships.\\nMore flexible but higher risk of overfitting.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "'''Polynomial regression is a type of regression analysis in which the relationship between the independent variable x and the dependent variable y \n",
    "is modeled as an n-th degree polynomial. It is used when the data shows a non-linear relationship between the variables.\n",
    "Differences from Linear Regression:\n",
    "Captures non-linear relationships.\n",
    "More flexible but higher risk of overfitting.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc1a368-3fb0-426f-9aa0-59c9b4e28a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Advantages:\\nFlexibility to model non-linear relationships.\\nBetter fit for non-linear data patterns.\\nIncreased predictive power for non-linear trends.\\nDisadvantages:\\nOverfitting risk, especially with high-degree polynomials.\\nComplexity and interpretability issues with higher-degree models.\\nExtrapolation issues leading to unreliable predictions outside the training data range.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use\n",
    "#polynomial regression?\n",
    "'''Advantages:\n",
    "Flexibility to model non-linear relationships.\n",
    "Better fit for non-linear data patterns.\n",
    "Increased predictive power for non-linear trends.\n",
    "Disadvantages:\n",
    "Overfitting risk, especially with high-degree polynomials.\n",
    "Complexity and interpretability issues with higher-degree models.\n",
    "Extrapolation issues leading to unreliable predictions outside the training data range.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fe849-86ef-4e01-9c05-a3135398ddca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
